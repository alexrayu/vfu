{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ANN (TensorFlow, Keras) for Spam Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of an ANN with Tensorflow + Keras.\n",
    "\n",
    "Built upon examples from the following sources:\n",
    "* https://medium.com/analytics-vidhya/spam-classification-with-tensorflow-keras-7e9fb8ace263\n",
    "* https://www.thepythoncode.com/article/build-spam-classifier-keras-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Definitions and early explanations.\n",
    "\n",
    "**TensorFlow** is a free and open source machine learning library and engine\n",
    " written and published by Google. See https://www.tensorflow.org.\n",
    "\n",
    "**A tensor** is a data array, similar to NumPy arrays. In a wide sense, all\n",
    "matrices are tensors. But in a narrow sense when used with **TensorFlow**,\n",
    "tensors are not alterable matrices, formatted for the use with GPUs.\n",
    "\n",
    "**Keras** is a free and open source API for TensorFlow, developed by the same\n",
    "team, that makes it faster and easier to use TensorFlow in general common\n",
    "scenarios. See https://keras.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:24.341448602Z",
     "start_time": "2023-10-05T14:16:24.230989547Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic stuff.\n",
    "import pandas as pd\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Feature engineering.\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Tensorflow and Keras.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Reporting and matrix.\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters.\n",
    "\n",
    "Hyper-parameters are the settings of our operations, especially as related to\n",
    "the Neural network.\n",
    "\n",
    "Changing the hyper-parameters can sometimes significantly influence the resulting\n",
    "performance and accuracy of results.\n",
    "\n",
    "**Dimensionality** of each layer is the size of it's output array, the amount of\n",
    "its artificial neurons.\n",
    "\n",
    "**DROP_SIZE** Is the severity of the dropout layer. If the drop size is 0.5,\n",
    "then the next NN layer will be proportionally smaller.\n",
    "\n",
    "The Dimensionality Base **DIM_BASE** hyper-parameter has started from 8000 and\n",
    "was gradually decreased until it started to affect the results in a negative\n",
    "way. It was possible to decrease the parameter from 8000 to 20 - 100 times,\n",
    "and that also proportionally decreased the training time of each layer from\n",
    "120s to 1s 5ms.\n",
    "\n",
    "I ended with the amount of 20 neurons, because when there was more than that,\n",
    "the model was overfit, and had some false positives. It's better to let a spam\n",
    "than to mark a non-spam as a positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:24.374755772Z",
     "start_time": "2023-10-05T14:16:24.249939140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Proportional size of the test subset.\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# Number of training epochs.\n",
    "EPOCHS = 5\n",
    "\n",
    "# The severity of the dropout layers.\n",
    "DROP_SIZE = 0.5\n",
    "\n",
    "# NN layer output dimensionality base.\n",
    "# There will be 4 such layers, each 2x smaller then the previous.\n",
    "DIM_BASE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the dataset.\n",
    "\n",
    "The source training csv file is a set of labeled emails, with \"spam\" value of 1\n",
    "and \"ham\" value of 0. The dataset was taken from\n",
    "https://github.com/Balakishan77/Spam-Email-Classifier/blob/master/spamham.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:24.437307835Z",
     "start_time": "2023-10-05T14:16:24.260795376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  spam\n0  naturally irresistible your corporate identity...     1\n1  the stock trading gunslinger  fanny is merrill...     1\n2  unbelievable new homes made easy  im wanting t...     1\n3  4 color printing special  request additional i...     1\n4  do not have money , get software cds from here...     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>naturally irresistible your corporate identity...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the stock trading gunslinger  fanny is merrill...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>unbelievable new homes made easy  im wanting t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4 color printing special  request additional i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>do not have money , get software cds from here...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emails.csv')\n",
    "df = df[['text', 'spam']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocess the dataset.\n",
    "\n",
    "Our dataset needs to be cleaned up - stopwords, punctuation, multiple spaces,\n",
    "etc.\n",
    "\n",
    "Pandas dataframe class has an `apply()` method that allows us to apply a custom\n",
    "function along the axis of a dataframe. See https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:27.283771952Z",
     "start_time": "2023-10-05T14:16:24.403751976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  spam\n0  naturally irresistible corporate identity lt r...     1\n1  stock trading gunslinger fanny merrill muzo co...     1\n2  unbelievable new homes made easy im wanting sh...     1\n3  4 color printing special request additional in...     1\n4  money get software cds software compatibility ...     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>spam</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>naturally irresistible corporate identity lt r...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>stock trading gunslinger fanny merrill muzo co...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>unbelievable new homes made easy im wanting sh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4 color printing special request additional in...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>money get software cds software compatibility ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the text - stopwords, punctuation, convert to lowercase.\n",
    "def text_processing(message):\n",
    "    stop_words = stopwords.words('english')\n",
    "    no_punctuation = [char for char in message if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stop_words])\n",
    "\n",
    "df['text'] = df['text'].apply(text_processing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split the dataset into training and testing subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:27.345106730Z",
     "start_time": "2023-10-05T14:16:27.285379523Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['text'].values\n",
    "y = df['spam'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature Engineering.\n",
    "\n",
    "### Vectorization.\n",
    "The text needs to be turned into numbers. `CountVectorizer()` will create a\n",
    "dictionary from the text (*fit*) and use to to onvert the text into these\n",
    "numbers (*transform*).\n",
    "\n",
    "We use the larger text body as a source of *fit*, and then serve that logic to\n",
    "itself, and the smaller training text body in *transform*.\n",
    "\n",
    "### Tf-Idf Vectorization.\n",
    "\n",
    "**TF-IDF** - Term Frequency times Inverse Document Frequency. It is a term\n",
    "weighing technique, where a given term is weighed higher if it's frequent to a\n",
    "document, but then weighed lower if it's a common word in other documents.\n",
    "\n",
    "The **tf-idf** is a probability calculator, that similar to how *Bayes* handles\n",
    "its probability calculation.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Tf-idf\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html.\n",
    "\n",
    "Resulting arrays are tokenized vectorized text with the token probability map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:28.364399370Z",
     "start_time": "2023-10-05T14:16:27.327573406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorization.\n",
    "bow = CountVectorizer()\n",
    "X_train = bow.fit_transform(X_train)\n",
    "X_test = bow.transform(X_test)\n",
    "\n",
    "# Term Frequency, Inverse Document Frequency.\n",
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Terminology.\n",
    "\n",
    "**Dense layers** - **linear** layers, a simple linear stack of NN layers.\n",
    "\n",
    "**Sequential model** - a model where each layer receives and returns 1 tensor.\n",
    "\n",
    "**Layer output dimensionality** - The size of the array the layer will output.\n",
    "\n",
    "### Explanation.\n",
    "\n",
    "The model class for this task is `Sequential()`, which is suitable for simple\n",
    "NNs where each layer has 1 input and 1 output tensor.\n",
    "\n",
    "See https://keras.io/guides/sequential_model.\n",
    "\n",
    "#### The dense (linear) layers.\n",
    "The model consists of 5 `Dense()` layers with decreasing output space\n",
    "dimensionality (\"units\"). 4 of which are activated by the *ReLU*, and the final\n",
    "one by the *sigmoid* activation function.\n",
    "\n",
    "Each new layer with smaller dimensionality thus raises the level of learning\n",
    "abstraction, until the final layer with the dimensionality of 1 remains and the\n",
    "final abstraction is *spam* or *ham* (1 or 0).\n",
    "\n",
    "See https://keras.io/api/layers/core_layers/dense.\n",
    "\n",
    "#### The dropout layers.\n",
    "To prevent bias and overfitting, we drop neurons at random by a certain rate. The dropout performed by the `Dropout()` layer. Is connected to the\n",
    "`Dense()` layer in such a way, that half of the neurons are dropped each time,\n",
    "and the each following layer is half-size smaller.\n",
    "\n",
    "See https://keras.io/api/layers/regularization_layers/dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:28.376963206Z",
     "start_time": "2023-10-05T14:16:28.358832395Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=DIM_BASE, activation='relu'))\n",
    "model.add(Dropout(DROP_SIZE))\n",
    "model.add(Dense(units=math.floor(DIM_BASE * DROP_SIZE), activation='relu'))\n",
    "model.add(Dropout(DROP_SIZE))\n",
    "model.add(Dense(units=math.floor(DIM_BASE * (DROP_SIZE * 2)), activation='relu'))\n",
    "model.add(Dropout(DROP_SIZE))\n",
    "model.add(Dense(units=math.floor(DIM_BASE* (DROP_SIZE * 4)), activation='relu'))\n",
    "model.add(Dropout(DROP_SIZE))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Compiling and training the model.\n",
    "\n",
    "After a model has been built, it needs to be compiled and then trained.\n",
    "\n",
    "### Compiler.\n",
    "Compiler prepared the built model for use. Compiler needs to be specified the\n",
    "parameters for *optimizer* and *loss* algorithms.\n",
    "\n",
    "**Optimizer** - the learning algorithm which adjusts the NN parameters,\n",
    "especially the *weights*, so as to achieve learning.\n",
    "\n",
    "See https://keras.io/api/optimizers.\n",
    "\n",
    "**Loss** - the loss evaluation algorithm. In our case, the *cross-entropy* loss\n",
    "algorithm calculates the cross-entropy loss between true labels and predicted\n",
    "labels.\n",
    "\n",
    "See https://keras.io/api/losses.\n",
    "\n",
    "See https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class.\n",
    "\n",
    "### Trainer.\n",
    "\n",
    "The model is trained with the `fit()` function. The callback parameter contains\n",
    "the *yearly_stop* instance, which will stop the learning process if the learning\n",
    "stops to improve the monitored results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:35.593180799Z",
     "start_time": "2023-10-05T14:16:28.378297020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 17:16:29.338559: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 624416632 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 2s 8ms/step - loss: 0.4491 - accuracy: 0.7591 - val_loss: 0.2070 - val_accuracy: 0.7670\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 1s 6ms/step - loss: 0.2279 - accuracy: 0.8957 - val_loss: 0.1394 - val_accuracy: 0.9904\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 1s 6ms/step - loss: 0.1363 - accuracy: 0.9747 - val_loss: 0.0623 - val_accuracy: 0.9913\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 1s 6ms/step - loss: 0.0950 - accuracy: 0.9756 - val_loss: 0.0270 - val_accuracy: 0.9939\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9804 - val_loss: 0.0192 - val_accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f9e7c72c910>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "\n",
    "# Stop training when the monitored metric has stopped improving.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "# Perform the training of the model.\n",
    "model.fit(x=X_train, y=y_train, epochs=EPOCHS, validation_data=(X_test, y_test), verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing the model.\n",
    "\n",
    "Predictions are performed on a test class. The *confusion matrix* and the\n",
    "*predictions classifications report* are calculated.\n",
    "\n",
    "**Classification report results explained:**\n",
    "* **Precision** – the accuracy of the predictions.\n",
    "* **Recall** – the accuracy of the *True Positives* predictions\n",
    "* **f1-score** – the accuracy of *True Positives* VS *False Positives* success.\n",
    "* **support** – the amount of the items of this class in the corpus.\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Confusion_matrix.\n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T14:16:36.164962112Z",
     "start_time": "2023-10-05T14:16:35.587513725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9939\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "[[875   4]\n",
      " [  3 264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       879\n",
      "           1       0.99      0.99      0.99       267\n",
      "\n",
      "    accuracy                           0.99      1146\n",
      "   macro avg       0.99      0.99      0.99      1146\n",
      "weighted avg       0.99      0.99      0.99      1146\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
